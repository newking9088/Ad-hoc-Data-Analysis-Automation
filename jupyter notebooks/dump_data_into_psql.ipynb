{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump Pandas DataFrame in PSQL\n",
    "Step 1: Create Connection\n",
    "<br>\n",
    "Step 2: Create Cursor\n",
    "<br>\n",
    "Step 3: Actual SQL\n",
    "<br>\n",
    "Step 4: Commit\n",
    "<br>\n",
    "Step 5: Close Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psycopg: PostgreSQL Adapter for Python\n",
    "\n",
    "Psycopg is the most popular PostgreSQL adapter used in Python. It works on the principle of the whole implementation of Python DB API 2.0 along with thread safety (the same connection is shared by multiple threads). It is designed to perform heavily multi-threaded applications that usually create and destroy lots of cursors and make a large number of simultaneous `INSERT` or `UPDATE` operations.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Thread Safety:** The same connection can be shared by multiple threads.\n",
    "- **High Performance:** Suitable for heavily multi-threaded applications.\n",
    "- **Client-side and Server-side Cursors:** Efficient data fetching and manipulation.\n",
    "- **Asynchronous Communication and Notification:** Allows for non-blocking database interactions.\n",
    "- **Unicode and Python 3 Friendly:** Fully supports Unicode and is compatible with Python 3.\n",
    "\n",
    "Psycopg is an excellent choice for applications that require robust and efficient interaction with PostgreSQL databases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'adhoc' already exists. Skipping creation.\n",
      "Data dumped into table 'testCell' successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DBCredentials:\n",
    "    \"\"\"\n",
    "    A dataclass to store database credentials.\n",
    "    \n",
    "    Attributes:\n",
    "        user (str): Username for the database.\n",
    "        password (str): Password for the database.\n",
    "        host (str): Host address of the database.\n",
    "        port (int): Port number to connect to the database.\n",
    "        dbname (str): Name of the database.\n",
    "    \"\"\"\n",
    "    user: str\n",
    "    password: str\n",
    "    host: str\n",
    "    port: int\n",
    "    dbname: str\n",
    "\n",
    "def load_credentials(json_file: str) -> DBCredentials:\n",
    "    \"\"\"\n",
    "    Load database credentials from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_file (str): Path to the JSON file containing the credentials.\n",
    "    \n",
    "    Returns:\n",
    "        DBCredentials: An instance of the DBCredentials dataclass.\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        creds_dict = json.load(file)\n",
    "    return DBCredentials(**creds_dict)\n",
    "\n",
    "def check_database_exists(creds: DBCredentials) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a database already exists.\n",
    "    \n",
    "    Args:\n",
    "        creds (DBCredentials): The database credentials.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the database exists, False otherwise.\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        host=creds.host,\n",
    "        user=creds.user,\n",
    "        password=creds.password,\n",
    "        database='postgres'  # Connect to the default 'postgres' database to check\n",
    "    )\n",
    "    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname='{creds.dbname}';\")\n",
    "    exists = cursor.fetchone() is not None\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return exists\n",
    "\n",
    "def create_db_and_dump_data(creds: DBCredentials, table_name: str, data_file: str, if_exists: str = 'replace'):\n",
    "    \"\"\"\n",
    "    Create a database (if it doesn't already exist) and dump data into a table.\n",
    "    \n",
    "    Args:\n",
    "        creds (DBCredentials): The database credentials.\n",
    "        table_name (str): The name of the table to create or append data to.\n",
    "        data_file (str): Path to the data file (Excel or CSV) to be dumped into the table.\n",
    "        if_exists (str): What to do if the table already exists. Options are 'replace' or 'append'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the database already exists\n",
    "        if not check_database_exists(creds):\n",
    "            # Connect to the default 'postgres' database to create the new database\n",
    "            default_conn = psycopg2.connect(\n",
    "                host=creds.host,\n",
    "                user=creds.user,\n",
    "                password=creds.password,\n",
    "                database='postgres'\n",
    "            )\n",
    "            default_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            default_cursor = default_conn.cursor()\n",
    "            default_cursor.execute(f\"CREATE DATABASE {creds.dbname};\")\n",
    "            print(f\"Database '{creds.dbname}' created successfully.\")\n",
    "            default_cursor.close()\n",
    "            default_conn.close()\n",
    "        else:\n",
    "            print(f\"Database '{creds.dbname}' already exists. Skipping creation.\")\n",
    "\n",
    "        # Connect to the target database using SQLAlchemy\n",
    "        engine = create_engine(f'postgresql+psycopg2://{creds.user}:{creds.password}@{creds.host}/{creds.dbname}')\n",
    "\n",
    "        # Determine the file extension and load the data accordingly\n",
    "        file_extension = os.path.splitext(data_file)[1].lower()\n",
    "        \n",
    "        if file_extension == '.xlsx':\n",
    "            df = pd.read_excel(data_file)\n",
    "        elif file_extension == '.csv':\n",
    "            df = pd.read_csv(data_file)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please use an Excel (.xlsx) or CSV (.csv) file.\")\n",
    "\n",
    "        # Dump data into the table\n",
    "        df.to_sql(table_name, engine, if_exists=if_exists, index=False)\n",
    "        print(f\"Data dumped into table '{table_name}' successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the table name and path to the data file\n",
    "    your_table_name = 'testCell'\n",
    "    data_to_dump_file_path = r\"C:\\Users\\anita\\OneDrive\\Desktop\\Ad-Hocs\\testCell.csv\"\n",
    "\n",
    "    # Load credentials from the JSON file\n",
    "    creds = load_credentials(r\"C:\\Users\\anita\\OneDrive\\Desktop\\Ad-Hocs\\db_credentials.json\")\n",
    "\n",
    "    # Create the database (if it doesn't exist) and dump data into the table\n",
    "    create_db_and_dump_data(creds, your_table_name, data_to_dump_file_path, if_exists = 'replace')  # Change 'replace' to 'append' if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
